{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_ratings():\n",
    "    COL_NAME = ['uid','mid','rating','timestamp']\n",
    "    df = pd.read_csv('./dataset/ml-1m/ratings.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
    "    return df\n",
    "\n",
    "def load_movies():\n",
    "    COL_NAME = ['mid','movie_name','movie_genre']\n",
    "    df = pd.read_csv('./dataset/ml-1m/movies.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
    "    return df\n",
    "\n",
    "def load_users():\n",
    "    COL_NAME = ['uid','user_fea1','user_fea2','user_fea3','user_fea4']\n",
    "    df = pd.read_csv('./dataset/ml-1m/users.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
    "    return df\n",
    "\n",
    "def text2seq(text, n_genre):\n",
    "    tokenizer = Tokenizer(lower=True, split='|',filters='', num_words=n_genre)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    seq = tokenizer.texts_to_sequences(text)\n",
    "    seq = pad_sequences(seq, maxlen=3,padding='post')\n",
    "    return seq\n",
    "\n",
    "def _model_fm_part(inputs, params):\n",
    "    \n",
    "    n_uid = params['n_uid']\n",
    "    n_mid = params['n_mid']\n",
    "    n_genre = params['n_genre']\n",
    "    k = params['k']\n",
    "    \n",
    "    input_uid, input_mid = inputs\n",
    "    \n",
    "    emb_uid = Embedding(n_uid + 1, output_dim=k, input_length=1, name = 'fm_emb_uid')(input_uid)\n",
    "    emb_uid = Flatten()(emb_uid)\n",
    "    emb_mid = Embedding(n_mid + 1, output_dim = k, input_length=1, name = 'fm_emb_mid')(input_mid)\n",
    "    emb_mid = Flatten()(emb_mid)\n",
    "    \n",
    "    return Multiply(name = 'fm_elementwise_mul')([emb_uid,emb_mid])\n",
    "\n",
    "def _model_mlp_part(inputs, params):\n",
    "        \n",
    "    input_uid, input_mid = inputs\n",
    "    mlp_layers = params['mlp_layers']\n",
    "    n_uid = params['n_uid']\n",
    "    n_mid = params['n_mid']\n",
    "    n_genre = params['n_genre']\n",
    "    k = params['k']\n",
    "    emb_uid = Embedding(n_uid + 1, k, input_length=1, name = 'mlp_emb_uid')(input_uid)\n",
    "    emb_uid = Flatten()(emb_uid)\n",
    "    emb_mid = Embedding(n_mid + 1, k, input_length=1, name = 'mlp_emb_mid')(input_mid)\n",
    "    emb_mid = Flatten()(emb_mid)\n",
    "    \n",
    "    output = concatenate([emb_uid, emb_mid])\n",
    "    for h in mlp_layers:\n",
    "        output = Dense(h, activation='relu')(output)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def df2xy(ratings):\n",
    "    x = [ratings.user_fea3.values, \n",
    "         ratings.uid.values, \n",
    "         ratings.mid.values, \n",
    "         np.concatenate(ratings.movie_genre.values).reshape(-1,3)]\n",
    "    y = ratings.rating.values\n",
    "    return x,y\n",
    "\n",
    "def deep_fm_model(n_uid, n_mid, n_genre, k, dnn_dim, dnn_dr):\n",
    "    # numerica features\n",
    "    fea4_input = Input((1,), name = 'input_fea4')\n",
    "    num_inputs = [fea4_input]\n",
    "    # single level categorical features\n",
    "    uid_input = Input((1,), name = 'input_uid')\n",
    "    mid_input = Input((1,), name= 'input_mid')\n",
    "    cat_sl_inputs = [uid_input, mid_input]\n",
    "\n",
    "    # multi level categorical features (with 3 genres at most)\n",
    "    genre_input = Input((3,), name = 'input_genre')\n",
    "    cat_ml_inputs = [genre_input]\n",
    "\n",
    "    inputs = num_inputs + cat_sl_inputs + cat_ml_inputs\n",
    "\n",
    "    # first order fm\n",
    "    # all tensors are reshape to (None, 1)\n",
    "    num_dense_1d = [Dense(1, name = 'num_dense_1d_fea4')(fea4_input)]\n",
    "    cat_sl_embed_1d = [Embedding(n_uid + 1, 1, name = 'cat_embed_1d_uid')(uid_input),\n",
    "                        Embedding(n_mid + 1, 1, name = 'cat_embed_1d_mid')(mid_input)]\n",
    "    cat_ml_embed_1d = [Embedding(n_genre + 1, 1, name = 'cat_embed_1d_genre')(genre_input)]\n",
    "\n",
    "    cat_sl_embed_1d = [Reshape((1,))(i) for i in cat_sl_embed_1d]\n",
    "    cat_ml_embed_1d = [Flatten()(i) for i in cat_ml_embed_1d]\n",
    "\n",
    "    # add all tensors\n",
    "    y_fm_1d = Add(name = 'fm_1d_output')(num_dense_1d + cat_sl_embed_1d + cat_ml_embed_1d)\n",
    "\n",
    "\n",
    "    # second order fm\n",
    "    # reshape all tensors to (None, k)\n",
    "    num_dense_2d = [Dense(k, name = 'num_dense_2d_fea4')(fea4_input)]\n",
    "    cat_sl_embed_2d = [Embedding(n_uid + 1, k, name = 'cat_embed_2d_uid')(uid_input), \n",
    "                       Embedding(n_mid + 1, k, name = 'cat_embed_2d_mid')(mid_input)]\n",
    "    cat_ml_embed_2d = [Embedding(n_genre + 1, k, name = 'cat_embed_2d_genre')(genre_input)]\n",
    "    cat_ml_embed_2d = [Lambda(lambda x: K.mean(x, axis=1), name = 'embed_2d_mean')(i) for i in cat_ml_embed_2d]\n",
    "\n",
    "    num_dense_2d = [Reshape((1,k))(i) for i in num_dense_2d]\n",
    "    cat_ml_embed_2d = [Reshape((1,k))(i) for i in cat_ml_embed_2d]\n",
    "\n",
    "    embed_2d = Concatenate(axis=1, name = 'concat_embed_2d')(num_dense_2d + cat_sl_embed_2d + cat_ml_embed_2d)\n",
    "\n",
    "    # calcuate the interactions by simplication\n",
    "    # sum of (x1*x2) = sum of (0.5*[(xi)^2 - (xi^2)])\n",
    "    tensor_sum = Lambda(lambda x: K.sum(x, axis = 1), name = 'sum_of_tensors')\n",
    "    tensor_square = Lambda(lambda x: K.square(x), name = 'square_of_tensors')\n",
    "\n",
    "    sum_of_embed = tensor_sum(embed_2d)\n",
    "    square_of_embed = tensor_square(embed_2d)\n",
    "\n",
    "    square_of_sum = Multiply()([sum_of_embed, sum_of_embed])\n",
    "    sum_of_square = tensor_sum(square_of_embed)\n",
    "\n",
    "    sub = Subtract()([square_of_sum, sum_of_square])\n",
    "    sub = Lambda(lambda x: x*0.5)(sub)\n",
    "    y_fm_2d = Reshape((1,), name = 'fm_2d_output')(tensor_sum(sub))\n",
    "\n",
    "\n",
    "    # dnn part\n",
    "    y_dnn = Flatten(name = 'flat_embed_2d')(embed_2d)\n",
    "    for h in dnn_dim:\n",
    "        y_dnn = Dropout(dnn_dr)(y_dnn)\n",
    "        y_dnn = Dense(h, activation='relu')(y_dnn)\n",
    "    y_dnn = Dense(1, activation='relu', name = 'deep_output')(y_dnn)\n",
    "\n",
    "    # combinded deep and fm parts\n",
    "    y = Concatenate()([y_fm_1d, y_fm_2d, y_dnn])\n",
    "    y = Dense(1, name = 'deepfm_output')(y)\n",
    "\n",
    "    fm_model_1d = Model(inputs, y_fm_1d)\n",
    "    fm_model_2d = Model(inputs, y_fm_2d)\n",
    "    deep_model = Model(inputs, y_dnn)\n",
    "    deep_fm_model = Model(inputs, y)\n",
    "    \n",
    "    return fm_model_1d, fm_model_2d, deep_model, deep_fm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid   mid  rating  timestamp\n",
      "0    1  1193       5  978300760\n",
      "1    1   661       3  978302109\n",
      "2    1   914       3  978301968\n",
      "3    1  3408       4  978300275\n",
      "4    1  2355       5  978824291\n",
      "   mid                          movie_name                   movie_genre\n",
      "0    1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1    2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2    3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3    4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4    5  Father of the Bride Part II (1995)                        Comedy\n",
      "   mid                          movie_name movie_genre\n",
      "0    1                    Toy Story (1995)   [9, 2, 0]\n",
      "1    2                      Jumanji (1995)   [7, 9, 0]\n",
      "2    3             Grumpier Old Men (1995)   [2, 5, 0]\n",
      "3    4            Waiting to Exhale (1995)   [2, 1, 0]\n",
      "4    5  Father of the Bride Part II (1995)   [2, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_genre</th>\n",
       "      <th>user_fea1</th>\n",
       "      <th>user_fea2</th>\n",
       "      <th>user_fea3</th>\n",
       "      <th>user_fea4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>[9, 13, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>[13, 5, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>[9, 2, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   mid  rating  timestamp                              movie_name  \\\n",
       "0    1  1193       5  978300760  One Flew Over the Cuckoo's Nest (1975)   \n",
       "1    1   661       3  978302109        James and the Giant Peach (1996)   \n",
       "2    1   914       3  978301968                     My Fair Lady (1964)   \n",
       "3    1  3408       4  978300275                  Erin Brockovich (2000)   \n",
       "4    1  2355       5  978824291                    Bug's Life, A (1998)   \n",
       "\n",
       "  movie_genre user_fea1  user_fea2  user_fea3 user_fea4  \n",
       "0   [1, 0, 0]         F          1         10     48067  \n",
       "1  [9, 13, 0]         F          1         10     48067  \n",
       "2  [13, 5, 0]         F          1         10     48067  \n",
       "3   [1, 0, 0]         F          1         10     48067  \n",
       "4   [9, 2, 0]         F          1         10     48067  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_genre = 15\n",
    "\n",
    "ratings = load_ratings()\n",
    "movies = load_movies()\n",
    "users = load_users()\n",
    "\n",
    "print(ratings.head())\n",
    "print(movies.head())\n",
    "\n",
    "movies['movie_genre'] = text2seq(movies.movie_genre.values, n_genre=n_genre).tolist()\n",
    "print(movies.head())\n",
    "\n",
    "ratings = ratings.join(movies.set_index('mid'), on = 'mid', how = 'left')\n",
    "ratings = ratings.join(users.set_index('uid'), on = 'uid', how = 'left')\n",
    "(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train_flag = np.random.random(len(ratings)) <= 0.9\n",
    "train_data = ratings.loc[in_train_flag,]\n",
    "valid_data = ratings.loc[~in_train_flag,]\n",
    "train_x, train_y = df2xy(train_data)\n",
    "valid_x, valid_y = df2xy(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_uid': ratings.uid.max(),\n",
    "    'n_mid': ratings.mid.max(),\n",
    "    'n_genre': 14,\n",
    "    'k':20,\n",
    "    'dnn_dim':[64,64],\n",
    "    'dnn_dr': 0.5\n",
    "}\n",
    "\n",
    "fm_model_1d, fm_model_2d, deep_model, deep_fm_model = deep_fm_model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuchr/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810005 samples, validate on 90001 samples\n",
      "Epoch 1/30\n",
      "810005/810005 [==============================] - 43s 54us/step - loss: 8.4493 - val_loss: 5.4553\n",
      "Epoch 2/30\n",
      "810005/810005 [==============================] - 41s 51us/step - loss: 1.4727 - val_loss: 4.4670\n",
      "Epoch 3/30\n",
      "810005/810005 [==============================] - 41s 51us/step - loss: 0.9880 - val_loss: 4.2425\n",
      "Epoch 4/30\n",
      "810005/810005 [==============================] - 41s 51us/step - loss: 0.9314 - val_loss: 4.1805\n",
      "Epoch 5/30\n",
      "810005/810005 [==============================] - 41s 50us/step - loss: 0.9130 - val_loss: 4.0764\n",
      "Epoch 6/30\n",
      "810005/810005 [==============================] - 41s 51us/step - loss: 0.9009 - val_loss: 3.9853\n",
      "Epoch 7/30\n",
      "810005/810005 [==============================] - 7s 8us/step - loss: 0.8910 - val_loss: 3.8919\n",
      "Epoch 8/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8811 - val_loss: 3.7791\n",
      "Epoch 9/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8712 - val_loss: 3.6231\n",
      "Epoch 10/30\n",
      "810005/810005 [==============================] - 6s 8us/step - loss: 0.8604 - val_loss: 3.5091\n",
      "Epoch 11/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8501 - val_loss: 3.3390\n",
      "Epoch 12/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8398 - val_loss: 3.2521\n",
      "Epoch 13/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8319 - val_loss: 3.1071\n",
      "Epoch 14/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8258 - val_loss: 2.9904\n",
      "Epoch 15/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8215 - val_loss: 2.8648\n",
      "Epoch 16/30\n",
      "810005/810005 [==============================] - 6s 8us/step - loss: 0.8179 - val_loss: 2.7827\n",
      "Epoch 17/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8150 - val_loss: 2.6894\n",
      "Epoch 18/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8123 - val_loss: 2.5439\n",
      "Epoch 19/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8096 - val_loss: 2.4454\n",
      "Epoch 20/30\n",
      "810005/810005 [==============================] - 6s 7us/step - loss: 0.8075 - val_loss: 2.3104\n",
      "Epoch 21/30\n",
      "810005/810005 [==============================] - 6s 8us/step - loss: 0.8053 - val_loss: 2.2156\n",
      "Epoch 22/30\n",
      "810005/810005 [==============================] - 9s 11us/step - loss: 0.8032 - val_loss: 2.1698\n",
      "Epoch 23/30\n",
      "810005/810005 [==============================] - 76s 93us/step - loss: 0.8007 - val_loss: 2.0537\n",
      "Epoch 24/30\n",
      "810005/810005 [==============================] - 193s 238us/step - loss: 0.7985 - val_loss: 1.9948\n",
      "Epoch 25/30\n",
      "196608/810005 [======>.......................] - ETA: 2:17 - loss: 0.7956"
     ]
    }
   ],
   "source": [
    "# train  model\n",
    "deep_fm_model.compile(loss = 'MSE', optimizer='adam')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks = [early_stop]\n",
    "deep_fm_model.fit(train_x, train_y, epochs=30, batch_size=2048, validation_split=0.1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(fm_model_1d, to_file='./image/fm_model_1d.png',show_shapes=True, show_layer_names=True)\n",
    "plot_model(fm_model_2d, to_file='./image/fm_model_2d.png',show_shapes=True, show_layer_names=True)\n",
    "plot_model(deep_model, to_file='./image/deep_model.png',show_shapes=True, show_layer_names=True)\n",
    "plot_model(deep_fm_model, to_file='./image/deep_fm_model.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st order FM model\n",
    "![title](./image/fm_model_1d.png)\n",
    "\n",
    "## 2nd order FM model\n",
    "![title](./image/fm_model_2d.png)\n",
    "\n",
    "## Deep model\n",
    "![title](./image/deep_model.png)\n",
    "\n",
    "## Deep FM model\n",
    "![title](./image/deep_fm_model.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
